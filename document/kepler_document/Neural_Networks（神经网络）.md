#神经网络
根据逻辑规则进行推理的过程

http://neuralnetworksanddeeplearning.com

神经网络：一种美妙的受生物学启发的编程范式，可以让计算机从观测数据中进行学习

深度学习：一个强有力的用于神经网络学习的众多技术的集合

神经网络和深度学习目前给出了在图像识别，语音识别和自然语言处理领域中很多问题的最好解决方案

##使用神经网络识别手写数字
人工神经元：感知机与S型神经元
###感知机
一个感知机接受几个二进制输入x1,x2,x3...，并产生一个二进制输出（逻辑门）output(0,1)

感知机引入权重，w1,w2,w3...,表示相应的输入对于输出重要性的实数，神经元的输出为0或1，则由分配权重后的总和x1w1 + x2w2 + x3w3 + ...小于或大于一定的阈值threshold,用代数形式表示：
	
	output = 0	（if x1w1 + x2w2 + x3w3 + ... <= threshold）
			 1	 (if x1w1 + x2w2 + x3w3 + ... > threshold)

训练过程为通过观测数据不断进行阈值的调整，知道阈值达到可以得到预想结果

设计学习算法，能够自动调整人工神经元的权重和偏置量，这种调整可以响应外部的刺激，不需要人工进行直接干预
###S型神经元
如何为一个神经网络设计学习算法？

使任何权重，偏置中的微小改动引起一个输出的微小改动

例如：假设网络错误的把一个“9”的图像分类为“8”，我们能够计算出怎么对权重和偏置做些小的改动，这样网络能够接近于把图像分类为“9”，重复这个过程，反复更改权重和偏置，产生更好的输出，这时网络就在学习。

**网络中的单个感知机上的权重或偏置的微小改动，有时会引起感知机输出的完全翻转，但是如果对某个输出结果进行调整权重或偏置，其他的输出结果会被完全改变**

**S型神经元和感知机类似，但是被修改为权重和偏置的微小波动只会引起输出的微小变化**

S型神经元有多个输入x1,x2,x3...取值为0到1的任意实数，并且对每个输入有权重w1,w2,w3...,和一个对所有输入的总偏置b，输出为ρ(w1x1 + w2x2 + w3x3 + ... + b),其中ρ（z） = 1/(1 + exp(-z)),**ρ（z）称为逻辑函数，该神经元为逻辑神经元**

ρ（z）的形状为S型，当z为很大的正数时，ρ（z）结果接近1；z为很小的负数时，ρ（z）结果接近0，ρ（z）函数的形式会简化微积分的计算

###神经网络构架
多层网络包含：输入层，输出层与隐藏层

例如：图像是一个64 X 64的灰度图像，会需要一个64 X 64 = 4096个输入神经元，每个强度取0和1之间合适的值。输出层只需包含一个神经元，当输出值小于0.5时表示“输入图像不是一个9”，小于0.5时表示“输入的图像是一个9”


###网络学习
目前讨论的只是**前馈神经网络**，还有**递归神经网络**，指ρ（z）函数的输入依赖于输出。递归神经网络更接近于大脑的实际工作情况

**梯度下降算法**可以用来进行学习，代价函数

训练算法的目的：最小化权重和偏置的代价函数C（w,b），随机梯度下降

例如：代价函数
	
C(w,b) = 1/2n[(y(x1) - a)^2 + (y(x2) - a)^2 + (y(x2) - a)^2 + ...]

>其中w：网络中权重的集合，b：所有的偏置

>n：训练输入数据的个数，x：训练输入，y(x)：当输入为x时，预期的输出；其中x,y(x)为向量

>a:当前输入x时，输出的向量为a

**如果要使C(w,b)尽量小，需要向量y(x)与a尽量相似**

**通过梯度下降法，在二维平面梯度场中，寻找“最小值”**

Python通过MNIST与Numpy的Python库

分类识别图像的灰暗度，可以使用SVM，支持向量机,scikit-learn Python库，提供了libSVM的C库

**复杂的算法 <= 简单的学习算法 + 好的训练数据**

###深度学习与深度学习网络

高级功能的识别需要将网络划分为多个子网络，子网络的结果为另一个子网络的输入

一个网络，将一个非常复杂的问题（一张图片是否有一张人脸）分解成在单像素层面上的网络，在子网络层，建立一个更加复杂和抽象的层级结构，形成深度学习网络

**反向传播算法（BackPropagtion），当梯度下降算法逼近代价函数的最小值时，计算平面场的代价函数梯度**